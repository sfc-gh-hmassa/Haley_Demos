{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "# Multimodal Multi-Hop RAG for Pump Datasheets\n",
    "\n",
    "This notebook extends the **multimodal RAG capabilities** from `CORTEX_SEARCH_MULTIMODAL_pumps_complete.ipynb` with **multi-hop reasoning** for complex cross-document analysis.\n",
    "\n",
    "## üîó What is Multi-Hop RAG?\n",
    "\n",
    "**Traditional Single-Hop**: Query ‚Üí Search ‚Üí Answer (may miss relevant information)\n",
    "\n",
    "**Multi-Hop RAG**: Query ‚Üí Initial Search ‚Üí Gap Analysis ‚Üí Follow-up Searches ‚Üí Comprehensive Answer\n",
    "\n",
    "## üéØ Perfect for Complex Pump Queries:\n",
    "\n",
    "- **Cross-vendor comparisons**: \"Compare NPSH requirements between Sulzer BE and Goulds 3196 pumps\"\n",
    "- **Comprehensive analysis**: \"Which pumps meet API 610 standards and what are their efficiency ratings?\"\n",
    "- **Multi-specification queries**: \"Find pumps suitable for high-temperature applications with materials list\"\n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "‚úÖ **Assumes you've completed**: `CORTEX_SEARCH_MULTIMODAL_pumps_complete.ipynb`\n",
    "\n",
    "- Multimodal search service: `DATASHEET_CORTEX_SEARCH_SERVICE`\n",
    "- Metadata tables: `DATASHEET_DIRECTORY`, `DATASHEET_PAGE_METADATA` \n",
    "- Vector embeddings and text indexes ready\n",
    "\n",
    "**This notebook adds**: Multi-hop reasoning layer on top of existing multimodal capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "from typing import List, Dict, Any, Set\n",
    "from snowflake.core import Root\n",
    "import snowflake.snowpark.session as session\n",
    "\n",
    "# Get active session and connect to existing search service\n",
    "session = get_active_session()\n",
    "root = Root(session)\n",
    "\n",
    "# Connect to the existing multimodal search service\n",
    "search_service = (root\n",
    "    .databases[\"DEMODB\"]\n",
    "    .schemas[\"DATASHEET_RAG\"]\n",
    "    .cortex_search_services[\"DATASHEET_CORTEX_SEARCH_SERVICE\"]\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Connected to existing multimodal search service\")\n",
    "print(\"üîó Ready for multi-hop RAG implementation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "name": "cell3"
   },
   "source": [
    "## Multi-Hop RAG Implementation\n",
    "\n",
    "The multi-hop approach performs iterative searches to ensure comprehensive coverage:\n",
    "\n",
    "1. **HOP 1**: Initial broad search using existing multimodal service\n",
    "2. **Analysis**: Identify gaps in vendor/product coverage\n",
    "3. **HOP 2+**: Targeted follow-up searches for missing information\n",
    "4. **Synthesis**: Combine results for comprehensive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "class MultiHopRAG:\n",
    "    \"\"\"Multi-hop RAG system built on existing multimodal search service\"\"\"\n",
    "    \n",
    "    def __init__(self, session, search_service):\n",
    "        self.session = session\n",
    "        self.search_service = search_service\n",
    "        \n",
    "    def embed_query(self, query_text: str) -> List[float]:\n",
    "        \"\"\"Generate embedding using the same model as the search service\"\"\"\n",
    "        sql_output = self.session.sql(\n",
    "            f\"\"\"SELECT SNOWFLAKE.CORTEX.EMBED_TEXT_1024('voyage-multimodal-3', \n",
    "                'Represent the query for retrieving supporting documents: {query_text}')\"\"\"\n",
    "        ).collect()\n",
    "        return list(sql_output[0].asDict().values())[0]\n",
    "    \n",
    "    def search_multimodal(self, query_text: str, limit: int = 10) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Use existing multimodal search service with both text and vector indexes\"\"\"\n",
    "        query_vector = self.embed_query(query_text)\n",
    "        \n",
    "        # Use the existing multi-index search pattern\n",
    "        resp = self.search_service.search(\n",
    "            multi_index_query={\n",
    "                \"TEXT\": [{\"text\": query_text}],\n",
    "                \"VECTOR_MAIN\": [{\"vector\": query_vector}]\n",
    "            },\n",
    "            columns=[\"TEXT\", \"PAGE_NUMBER\", \"IMAGE_FILEPATH\", \"VENDOR\", \"PRODUCT_ID\", \n",
    "                    \"PUMP_MODEL\", \"DATASHEET_TYPE\", \"SECTION_TITLE\"],\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        return resp.to_dict()[\"results\"]\n",
    "    \n",
    "    def analyze_coverage_gaps(self, results: List[Dict], original_query: str) -> List[str]:\n",
    "        \"\"\"Identify gaps in vendor/product coverage for follow-up searches\"\"\"\n",
    "        found_vendors = set(r.get('VENDOR', 'Unknown') for r in results)\n",
    "        found_products = set(r.get('PRODUCT_ID', 'Unknown') for r in results)\n",
    "        \n",
    "        print(f\"üìä Coverage Analysis:\")\n",
    "        print(f\"   Found vendors: {', '.join(found_vendors)}\")\n",
    "        print(f\"   Found products: {', '.join(found_products)}\")\n",
    "        \n",
    "        # Generate follow-up queries based on gaps and query type\n",
    "        follow_up_queries = []\n",
    "        \n",
    "        # For comparison queries, ensure we search all major vendors\n",
    "        if any(word in original_query.lower() for word in ['compare', 'which', 'best', 'highest', 'vs']):\n",
    "            major_vendors = ['Sulzer', 'Goulds', 'Fristam']\n",
    "            for vendor in major_vendors:\n",
    "                if vendor not in found_vendors:\n",
    "                    follow_up_queries.append(f\"{vendor} {original_query}\")\n",
    "        \n",
    "        # For specification queries, search by technical terms\n",
    "        if any(term in original_query.lower() for term in ['npsh', 'efficiency', 'flow', 'pressure', 'api']):\n",
    "            # Extract key technical terms for targeted search\n",
    "            tech_terms = []\n",
    "            if 'npsh' in original_query.lower():\n",
    "                tech_terms.append('NPSH required suction head')\n",
    "            if 'efficiency' in original_query.lower():\n",
    "                tech_terms.append('pump efficiency BEP')\n",
    "            if 'api 610' in original_query.lower():\n",
    "                tech_terms.append('API 610 standard compliance')\n",
    "            \n",
    "            for term in tech_terms[:2]:  # Limit follow-ups\n",
    "                follow_up_queries.append(f\"{term} specifications\")\n",
    "        \n",
    "        return follow_up_queries[:3]  # Limit to 3 follow-up queries\n",
    "    \n",
    "    def multi_hop_search(self, original_query: str, max_hops: int = 4) -> Dict[str, Any]:\n",
    "        \"\"\"Perform multi-hop search for comprehensive coverage\"\"\"\n",
    "        print(f\"üîç Multi-Hop Search: {original_query}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        all_results = []\n",
    "        search_history = []\n",
    "        \n",
    "        # HOP 1: Initial broad search\n",
    "        print(f\"\\nüìç HOP 1: Initial multimodal search\")\n",
    "        initial_results = self.search_multimodal(original_query, limit=8)\n",
    "        all_results.extend(initial_results)\n",
    "        search_history.append({\n",
    "            \"hop\": 1, \n",
    "            \"query\": original_query, \n",
    "            \"results_count\": len(initial_results)\n",
    "        })\n",
    "        \n",
    "        self._display_results(initial_results[:3], \"Initial Results\")\n",
    "        \n",
    "        # Analyze gaps and generate follow-up queries\n",
    "        follow_up_queries = self.analyze_coverage_gaps(initial_results, original_query)\n",
    "        \n",
    "        # HOP 2+: Follow-up searches\n",
    "        for hop_num, follow_up_query in enumerate(follow_up_queries, 2):\n",
    "            if hop_num > max_hops:\n",
    "                break\n",
    "                \n",
    "            print(f\"\\nüìç HOP {hop_num}: Follow-up search\")\n",
    "            print(f\"   Query: {follow_up_query}\")\n",
    "            \n",
    "            hop_results = self.search_multimodal(follow_up_query, limit=5)\n",
    "            \n",
    "            # Filter out duplicates based on IMAGE_FILEPATH\n",
    "            existing_paths = {r.get('IMAGE_FILEPATH') for r in all_results}\n",
    "            new_results = [r for r in hop_results if r.get('IMAGE_FILEPATH') not in existing_paths]\n",
    "            \n",
    "            if new_results:\n",
    "                all_results.extend(new_results)\n",
    "                search_history.append({\n",
    "                    \"hop\": hop_num,\n",
    "                    \"query\": follow_up_query,\n",
    "                    \"results_count\": len(new_results)\n",
    "                })\n",
    "                self._display_results(new_results[:2], f\"Hop {hop_num} New Results\")\n",
    "            else:\n",
    "                print(f\"   No new results found\")\n",
    "        \n",
    "        return {\n",
    "            \"original_query\": original_query,\n",
    "            \"all_results\": all_results,\n",
    "            \"search_history\": search_history,\n",
    "            \"total_documents\": len(all_results)\n",
    "        }\n",
    "    \n",
    "    def _display_results(self, results: List[Dict], title: str):\n",
    "        \"\"\"Display search results in formatted way\"\"\"\n",
    "        print(f\"\\nüìã {title}:\")\n",
    "        for i, result in enumerate(results, 1):\n",
    "            vendor = result.get('VENDOR', 'N/A')\n",
    "            product = result.get('PRODUCT_ID', 'N/A')\n",
    "            page = result.get('PAGE_NUMBER', 'N/A')\n",
    "            section = result.get('SECTION_TITLE', 'N/A')\n",
    "            print(f\"   {i}. {vendor} {product} - Page {page} ({section})\")\n",
    "    \n",
    "    def generate_comprehensive_answer(self, search_data: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate comprehensive answer using all multi-hop results\"\"\"\n",
    "        print(f\"\\nü§ñ Generating comprehensive answer from {search_data['total_documents']} documents...\")\n",
    "        \n",
    "        # Group results by vendor for structured analysis\n",
    "        results_by_vendor = {}\n",
    "        for result in search_data[\"all_results\"]:\n",
    "            vendor = result.get('VENDOR', 'Unknown')\n",
    "            if vendor not in results_by_vendor:\n",
    "                results_by_vendor[vendor] = []\n",
    "            results_by_vendor[vendor].append(result)\n",
    "        \n",
    "        # Create structured context for LLM\n",
    "        context_parts = []\n",
    "        for vendor, results in results_by_vendor.items():\n",
    "            context_parts.append(f\"\\n=== {vendor} Data ===\")\n",
    "            for result in results[:2]:  # Top 2 results per vendor\n",
    "                product = result.get('PRODUCT_ID', 'Unknown')\n",
    "                page = result.get('PAGE_NUMBER', 'Unknown')\n",
    "                section = result.get('SECTION_TITLE', 'General')\n",
    "                text_content = str(result.get('TEXT', ''))[:400]\n",
    "                \n",
    "                context_parts.append(\n",
    "                    f\"Product: {product} (Page {page}, {section})\\n\"\n",
    "                    f\"Content: {text_content}...\"\n",
    "                )\n",
    "        \n",
    "        context = \"\\n\".join(context_parts)\n",
    "        \n",
    "        # Generate comprehensive answer\n",
    "        prompt = f\"\"\"\n",
    "        Question: {search_data['original_query']}\n",
    "        \n",
    "        I performed a multi-hop search across pump datasheets and gathered the following information:\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Please provide a comprehensive answer that:\n",
    "        1. Directly answers the original question\n",
    "        2. Compares information across different vendors when relevant\n",
    "        3. Cites specific sources (vendor, product, page) for key facts\n",
    "        4. Highlights any gaps in available information\n",
    "        5. Provides actionable insights for pump selection\n",
    "        \n",
    "        Focus on technical accuracy and practical engineering insights.\n",
    "        \"\"\"\n",
    "        \n",
    "        sql = \"SELECT SNOWFLAKE.CORTEX.COMPLETE('llama3.1-70b', ?) as answer\"\n",
    "        result = self.session.sql(sql, params=[prompt]).collect()[0]\n",
    "        \n",
    "        answer = result[\"ANSWER\"]\n",
    "        \n",
    "        # Display search summary\n",
    "        print(f\"\\nüìä Multi-Hop Search Summary:\")\n",
    "        for search in search_data['search_history']:\n",
    "            print(f\"   Hop {search['hop']}: {search['results_count']} results\")\n",
    "        \n",
    "        print(f\"\\nüí° Comprehensive Answer:\")\n",
    "        print(answer)\n",
    "        \n",
    "        return answer\n",
    "\n",
    "# Initialize multi-hop RAG system using existing search service\n",
    "multihop_rag = MultiHopRAG(session, search_service)\n",
    "print(\"üöÄ Multi-hop RAG system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe518f6-7a2e-4cae-8855-5330239082fa",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "# Complex comparison query that benefits from multi-hop search\n",
    "comparison_query = \"Cmopare NPSH required at 120% flow for Goulds 3196 vs Sulzer BE. Which is lower and what are the values?\"\n",
    "\n",
    "# Perform multi-hop search\n",
    "search_results = multihop_rag.multi_hop_search(comparison_query, max_hops=4)\n",
    "\n",
    "# Generate comprehensive answer\n",
    "final_answer = multihop_rag.generate_comprehensive_answer(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": [
    "## Example 1: Cross-Vendor NPSH Comparison\n",
    "\n",
    "This demonstrates how multi-hop search ensures comprehensive coverage across all vendors for comparison queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# Complex comparison query that benefits from multi-hop search\n",
    "comparison_query = \"Compare NPSH requirements between Sulzer BE and Goulds 3196 pumps at high flow rates\"\n",
    "\n",
    "# Perform multi-hop search\n",
    "search_results = multihop_rag.multi_hop_search(comparison_query, max_hops=4)\n",
    "\n",
    "# Generate comprehensive answer\n",
    "final_answer = multihop_rag.generate_comprehensive_answer(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "name": "cell7"
   },
   "source": [
    "## Example 2: API 610 Compliance Analysis\n",
    "\n",
    "Multi-hop search excels at finding all pumps meeting specific standards across different datasheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "# Standards compliance query\n",
    "standards_query = \"Which pumps meet API 610 standards and what are their efficiency ratings and material specifications?\"\n",
    "\n",
    "# Perform multi-hop search\n",
    "search_results = multihop_rag.multi_hop_search(standards_query, max_hops=4)\n",
    "\n",
    "# Generate comprehensive answer\n",
    "final_answer = multihop_rag.generate_comprehensive_answer(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "name": "cell9"
   },
   "source": [
    "## Example 3: High-Temperature Application Requirements\n",
    "\n",
    "Complex application queries often require information from multiple sections and datasheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "# Application-specific query\n",
    "application_query = \"What pumps are suitable for high-temperature corrosive applications and what materials and sealing systems are used?\"\n",
    "\n",
    "# Perform multi-hop search\n",
    "search_results = multihop_rag.multi_hop_search(application_query, max_hops=3)\n",
    "\n",
    "# Generate comprehensive answer\n",
    "final_answer = multihop_rag.generate_comprehensive_answer(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "name": "cell11"
   },
   "source": [
    "## Enhanced Analysis: Single-Hop vs Multi-Hop Comparison\n",
    "\n",
    "Let's compare the effectiveness of single-hop vs multi-hop approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "def compare_approaches(query: str):\n",
    "    \"\"\"Compare single-hop vs multi-hop search results\"\"\"\n",
    "    print(f\"üìä Comparing Single-Hop vs Multi-Hop: {query}\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Single-hop search (just initial search)\n",
    "    print(\"\\nüîç Single-Hop Results:\")\n",
    "    single_results = multihop_rag.search_multimodal(query, limit=10)\n",
    "    single_vendors = set(r.get('VENDOR', 'Unknown') for r in single_results)\n",
    "    single_products = set(r.get('PRODUCT_ID', 'Unknown') for r in single_results)\n",
    "    \n",
    "    print(f\"   Documents: {len(single_results)}\")\n",
    "    print(f\"   Vendors: {len(single_vendors)} ({', '.join(single_vendors)})\")\n",
    "    print(f\"   Products: {len(single_products)}\")\n",
    "    \n",
    "    # Multi-hop search\n",
    "    print(\"\\nüîó Multi-Hop Results:\")\n",
    "    multihop_data = multihop_rag.multi_hop_search(query, max_hops=3)\n",
    "    multihop_results = multihop_data[\"all_results\"]\n",
    "    multihop_vendors = set(r.get('VENDOR', 'Unknown') for r in multihop_results)\n",
    "    multihop_products = set(r.get('PRODUCT_ID', 'Unknown') for r in multihop_results)\n",
    "    \n",
    "    print(f\"   Documents: {len(multihop_results)}\")\n",
    "    print(f\"   Vendors: {len(multihop_vendors)} ({', '.join(multihop_vendors)})\")\n",
    "    print(f\"   Products: {len(multihop_products)}\")\n",
    "    print(f\"   Search Hops: {len(multihop_data['search_history'])}\")\n",
    "    \n",
    "    # Analysis\n",
    "    print(\"\\nüìà Improvement Analysis:\")\n",
    "    print(f\"   üìÑ Additional documents: +{len(multihop_results) - len(single_results)}\")\n",
    "    print(f\"   üè≠ Additional vendors: +{len(multihop_vendors - single_vendors)}\")\n",
    "    print(f\"   üîß Additional products: +{len(multihop_products - single_products)}\")\n",
    "    \n",
    "    new_vendors = multihop_vendors - single_vendors\n",
    "    if new_vendors:\n",
    "        print(f\"   ‚ú® New vendors discovered: {', '.join(new_vendors)}\")\n",
    "    \n",
    "    return {\n",
    "        \"single_hop\": {\"results\": single_results, \"vendors\": single_vendors},\n",
    "        \"multi_hop\": {\"results\": multihop_results, \"vendors\": multihop_vendors}\n",
    "    }\n",
    "\n",
    "# Test comparison with a complex query\n",
    "test_query = \"Compare efficiency and flow rate capabilities across pump models\"\n",
    "comparison_results = compare_approaches(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "name": "cell13"
   },
   "source": [
    "## Interactive Multi-Hop Query Interface\n",
    "\n",
    "Test different types of complex queries with the multi-hop system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "# Sample complex queries for testing\n",
    "sample_queries = [\n",
    "    \"Compare NPSH requirements and efficiency across all pump vendors\",\n",
    "    \"Which pumps have the highest pressure ratings and what materials are used?\",\n",
    "    \"Find pumps suitable for chemical processing with corrosion resistance details\",\n",
    "    \"What are the dimensional requirements and installation considerations for API pumps?\",\n",
    "    \"Compare maintenance intervals and service procedures across pump types\"\n",
    "]\n",
    "\n",
    "print(\"üöÄ Multi-Hop RAG Demo - Sample Complex Queries:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "for i, query in enumerate(sample_queries, 1):\n",
    "    print(f\"{i}. {query}\")\n",
    "\n",
    "# Run a sample query (change index to test different queries)\n",
    "selected_query = sample_queries[0]\n",
    "print(f\"\\nüéØ Running: {selected_query}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Execute multi-hop search\n",
    "demo_results = multihop_rag.multi_hop_search(selected_query, max_hops=4)\n",
    "demo_answer = multihop_rag.generate_comprehensive_answer(demo_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "name": "cell15"
   },
   "source": [
    "## Summary: Multi-Hop RAG Benefits\n",
    "\n",
    "### ‚úÖ When Multi-Hop RAG Excels:\n",
    "\n",
    "- **Cross-vendor comparisons**: Ensures all major vendors are included\n",
    "- **Standards compliance**: Finds all pumps meeting specific criteria\n",
    "- **Complex specifications**: Gathers comprehensive technical data\n",
    "- **Application analysis**: Combines requirements from multiple sources\n",
    "\n",
    "### ‚ö° Performance Considerations:\n",
    "\n",
    "- **Latency**: 2-4x longer due to multiple search hops\n",
    "- **Cost**: Additional API calls for embeddings and completions\n",
    "- **Accuracy**: Better coverage but requires careful result filtering\n",
    "\n",
    "### üéØ Best Practices:\n",
    "\n",
    "1. **Use for complex queries**: Simple factual queries work fine with single-hop\n",
    "2. **Limit hops**: Start with 3-4 hops, adjust based on results\n",
    "3. **Filter duplicates**: Remove redundant results between hops\n",
    "4. **Gap analysis**: Focus follow-ups on missing vendor/product coverage\n",
    "\n",
    "### üîß Integration with Existing System:\n",
    "\n",
    "This multi-hop layer seamlessly extends your existing multimodal RAG system:\n",
    "- ‚úÖ Uses same search service and embeddings\n",
    "- ‚úÖ Leverages existing metadata and attributes\n",
    "- ‚úÖ Compatible with current Streamlit apps\n",
    "- ‚úÖ No additional setup or data processing required"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "lastEditStatus": {
   "authorEmail": "haley.massa@snowflake.com",
   "authorId": "3366391852320",
   "authorName": "HMASSA",
   "lastEditTime": 1756777147326,
   "notebookId": "7nxaxeazdymbu3wmw6at",
   "sessionId": "ed590d50-62b0-4925-a794-74d8f26d42f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
