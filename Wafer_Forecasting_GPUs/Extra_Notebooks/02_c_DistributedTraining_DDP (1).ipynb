{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "df5y6krd3kv3zlzqzgbz",
   "authorId": "3366391852320",
   "authorName": "HMASSA",
   "authorEmail": "haley.massa@snowflake.com",
   "sessionId": "33cb5133-46d6-4c0d-b131-8cae3a1d8abd",
   "lastEditTime": 1766423301344
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": [
    "# üìò Notebook 2c: Distributed Data Parallel (DDP) Training with Snowflake\n",
    "\n",
    "## Native PyTorch DDP using `PyTorchDistributor`\n",
    "\n",
    "Snowflake **natively supports PyTorch Distributed Data Parallel (DDP)** training through the `PyTorchDistributor` API. This allows you to run distributed training at scale without managing your own cluster or orchestration layer.\n",
    "\n",
    "### When to Consider DDP\n",
    "\n",
    "DDP is beneficial when:\n",
    "\n",
    "- **Training time is a bottleneck** ‚Äî Epochs take too long on a single GPU\n",
    "- **Multiple GPUs are available** ‚Äî You have 2+ GPUs you want to utilize\n",
    "- **GPU utilization is already high** ‚Äî Single GPU is near 100% but still slow\n",
    "- **Data loading isn't the bottleneck** ‚Äî If data loading is slow, DDP won't help\n",
    "\n",
    "DDP may be overkill when:\n",
    "\n",
    "- **Training completes quickly** ‚Äî A few minutes per epoch on single GPU\n",
    "- **GPU utilization is low** ‚Äî Indicates data loading or CPU bottleneck\n",
    "- **Only 1 GPU available** ‚Äî DDP requires multiple GPUs\n",
    "\n",
    "> ‚ö†Ô∏è **Note:** There are no universal dataset size thresholds. Whether DDP helps depends on your specific model, batch size, hardware, and data pipeline. Profile first, then decide.\n",
    "\n",
    "### How Snowflake DDP Works\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   PyTorchDistributor                         ‚îÇ\n",
    "‚îÇ                                                              ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ   ‚îÇ              Your Training Function                  ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ  ‚Ä¢ Uses standard PyTorch DDP APIs                   ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ  ‚Ä¢ Gets rank/world_size from get_context()          ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ  ‚Ä¢ Wraps model with DistributedDataParallel         ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ                           ‚Üì                                  ‚îÇ\n",
    "‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ   ‚îÇ  GPU 0   ‚îÇ  ‚îÇ  GPU 1   ‚îÇ  ‚îÇ  GPU 2   ‚îÇ  ‚îÇ  GPU 3   ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ  Rank 0  ‚îÇ  ‚îÇ  Rank 1  ‚îÇ  ‚îÇ  Rank 2  ‚îÇ  ‚îÇ  Rank 3  ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ  Model   ‚îÇ  ‚îÇ  Model   ‚îÇ  ‚îÇ  Model   ‚îÇ  ‚îÇ  Model   ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îÇ  Copy    ‚îÇ  ‚îÇ  Copy    ‚îÇ  ‚îÇ  Copy    ‚îÇ  ‚îÇ  Copy    ‚îÇ   ‚îÇ\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ        ‚îÇ             ‚îÇ             ‚îÇ             ‚îÇ          ‚îÇ\n",
    "‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ\n",
    "‚îÇ                             ‚Üì                               ‚îÇ\n",
    "‚îÇ                   Gradient AllReduce                        ‚îÇ\n",
    "‚îÇ                   (Handled automatically)                   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| `ShardedDataConnector` | Automatically partitions data across workers |\n",
    "| `PyTorchDistributor` | Manages distributed training orchestration |\n",
    "| `PyTorchScalingConfig` | Configures nodes, workers, and resources |\n",
    "| `get_context()` | Provides rank, local_rank, dataset_map inside training function |\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- [Snowflake PyTorchDistributor Documentation](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/latest/container-runtime/distributors.pytorch_distributor)\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "code",
   "id": "2049ca83-8951-409a-92bd-3d1e17db6d4b",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": " -- Run this SQL to increase your pool capacity to 3 nodes                      \n ALTER COMPUTE POOL WAFER_TRAINING_POOL SET MAX_NODES = 3;   ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac976934-24a6-4c38-b9ee-5f5f5273253e",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "session.sql(\"DESCRIBE COMPUTE POOL WAFER_TRAINING_POOL\").show() ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell2",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# ============================================================================\n# IMPORTS\n# ============================================================================\n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\n\n# PyTorch imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Snowpark imports\nfrom snowflake.snowpark.context import get_active_session\n\n# Snowflake ML Dataset imports\nfrom snowflake.ml import dataset\n\n# Snowflake ML Data imports\nfrom snowflake.ml.data import DataConnector\nfrom snowflake.ml.data.sharded_data_connector import ShardedDataConnector\n\n# Snowflake Distributed Training imports\nfrom snowflake.ml.modeling.distributors.pytorch import (\n    PyTorchDistributor,\n    PyTorchScalingConfig,\n    WorkerResourceConfig\n)\n\nprint(\"‚úÖ Imports complete\")\nprint(f\"   PyTorch: {torch.__version__}\")\nprint(f\"   CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"   GPU count: {torch.cuda.device_count()}\")\n",
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell3",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SNOWFLAKE SESSION\n",
    "# ============================================================================\n",
    "\n",
    "session = get_active_session()\n",
    "\n",
    "session.sql(\"USE DATABASE WAFER_YIELD_DEMO\").collect()\n",
    "session.sql(\"USE SCHEMA RAW_DATA\").collect()\n",
    "\n",
    "print(f\"‚úÖ Session active\")\n",
    "print(f\"   Database: {session.get_current_database()}\")\n",
    "print(f\"   Schema: {session.get_current_schema()}\")\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000002"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "---\n\n## üìò Section 1 ‚Äî Load Data with ShardedDataConnector\n\nThe `ShardedDataConnector` automatically partitions data across distributed workers. Each worker receives a unique shard of the data.\n\nWhy use ShardedDataConnector:                                                   \n\n ‚Ä¢ Each GPU worker gets a unique subset of your XX rows                       \n ‚Ä¢ Prevents memory overflow on individual GPUs                                  \n ‚Ä¢ Required for PyTorch DDP to work correctly (each worker needs different data)\n ‚Ä¢ Automatically partitions data across your workers \n",
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell5",
    "language": "python"
   },
   "outputs": [],
   "source": "# ============================================================================\n# LOAD ML DATASET\n# ============================================================================\n\n# Fully qualified dataset name (created in Notebook 01)\nDATASET_NAME = \"WAFER_YIELD_DEMO.RAW_DATA.WAFER_YIELD_TRAINING_DATASET\"\nDATASET_VERSION = \"v1\"\n\n# Load ML Dataset\nprint(f\"üì¶ Loading ML Dataset: {DATASET_NAME}\")\nwafer_dataset = dataset.load_dataset(session, DATASET_NAME, DATASET_VERSION)\n\n# Create DataConnector from the dataset\nsharded_data_connector = ShardedDataConnector.from_dataset(wafer_dataset)  \n\n# For DDP, we'll convert to ShardedDataConnector later in the training function\n# For now, get the Snowpark DataFrame to inspect columns\ntraining_df = wafer_dataset.read.to_snowpark_dataframe()\n\n# Define feature and label columns\nEXCLUDE_COLS = ['WAFER_ID', 'YIELD_GOOD', 'YIELD_SCORE', 'DOMINANT_DEFECT_TYPE']\n\n# Get column names from the dataframe\nall_cols = [f.name for f in training_df.schema.fields]                         \ninput_cols = [c for c in all_cols if c.upper() not in [x.upper() for x in      \n EXCLUDE_COLS]]                                                                 \nlabel_col = 'YIELD_GOOD'   \n\nfrom snowflake.ml.runtime_cluster import scale_cluster, get_nodes               \n\nprint(\"Scaling cluster to 2 nodes for 2-GPU training...\") \nscale_cluster(2)  #   This may take a few minutes   \n\nnodes = get_nodes() \nprint(f\"Active nodes: {len(nodes)}\") \nprint(f\"Node details:  {nodes}\")     ",
   "id": "ce110000-1111-2222-3333-ffffff000004"
  },
  {
   "cell_type": "code",
   "id": "0dd52b78-3508-40e1-89d0-0355ade20164",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "print(\"ML Dataset loaded:\", DATASET_NAME) \nprint(\"Total columns:\", len(all_cols))\nprint(\"Feature columns:\", len(input_cols)) \nprint(\"Label column:\", label_col)    \nprint(\"Features:\", input_cols[:5]) ",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## üìò Section 2 ‚Äî Define Model Architecture\n",
    "\n",
    "Define the DNN model that will be trained with DDP. The model itself is standard PyTorch ‚Äî DDP wrapping happens inside the training function.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000005"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell7",
    "language": "python"
   },
   "outputs": [],
   "source": "# ============================================================================\n# DEFINE MODEL ARCHITECTURE\n# ============================================================================\n\nclass WaferYieldDNN(nn.Module):                                                \n     \"\"\"                                                                        \n     Deep Neural Network for wafer yield classification.                        \n                                                                                \n     Architecture:                                                              \n         Input ‚Üí 128 ‚Üí ReLU ‚Üí BN ‚Üí Dropout ‚Üí 64 ‚Üí ReLU ‚Üí BN ‚Üí Dropout ‚Üí 1 ‚Üí     \n Sigmoid                                                                        \n     \"\"\"                                                                        \n                                                                                \n     def __init__(self, input_size, hidden_size=128, output_size=1,             \n dropout_p=0.3):                                                                \n         super(WaferYieldDNN, self).__init__()                                  \n                                                                                \n         self.network = nn.Sequential(                                          \n             nn.Linear(input_size, hidden_size),                                \n             nn.ReLU(),                                                         \n             nn.BatchNorm1d(hidden_size),                                       \n             nn.Dropout(dropout_p),                                             \n             nn.Linear(hidden_size, hidden_size // 2),                          \n             nn.ReLU(),                                                         \n             nn.BatchNorm1d(hidden_size // 2),                                  \n             nn.Dropout(dropout_p * 0.67),  # Slightly less dropout in second layer                                                                          \n             nn.Linear(hidden_size // 2, output_size),                          \n             nn.Sigmoid()                                                       \n         )                                                                      \n                                                                                \n     def forward(self, x):                                                      \n         return self.network(x)                                                 \n                                                                                \n\nprint(\"Model architecture defined\") \nprint(\"Input size:\", len(input_cols))       \nprint(\"Hidden layers: 128 -> 64\") \nprint(\"Output: Binary classification (Sigmoid)\")      \n",
   "id": "ce110000-1111-2222-3333-ffffff000006"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "---\n\n## üìò Section 3 ‚Äî Define DDP Training Function\n\nThe training function runs on each distributed worker. Key patterns:\n\n1. **Import inside the function** ‚Äî Ensures workers have access to modules\n2. **`get_context()`** ‚Äî Provides rank, local_rank, dataset_map, model_dir\n3. **`init_process_group`** ‚Äî Initializes DDP communication\n4. **`DDP(model)`** ‚Äî Wraps model for gradient synchronization\n5. **`get_shard()`** ‚Äî Each worker gets its unique data partition\n6. **Save on rank 0 only** ‚Äî Prevents duplicate saves\n\n ‚Ä¢ PyTorchTrainer setup                                                         \n ‚Ä¢ ScalingConfig with num_nodes and num_workers_per_node                        \n ‚Ä¢ Training function with dist.init_process_group() and DDP wrapper             \n ‚Ä¢ DataLoader creation from sharded data    \n",
   "id": "ce110000-1111-2222-3333-ffffff000007"
  },
  {
   "cell_type": "code",
   "id": "0dc90893-0e82-42cd-989d-0cf290e7313e",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": "# ============================================================================\n# DEFINE DDP TRAINING FUNCTION\n# ============================================================================\n\n# Store column info for access inside training function\nINPUT_COLS = input_cols\nLABEL_COL = label_col\nINPUT_SIZE = len(input_cols)\n\ndef train_ddp_func():\n    \"\"\"DDP training function that runs on each worker.\"\"\"\n    import os\n    import torch\n    import torch.nn as nn\n    import torch.optim as optim\n    import torch.distributed as dist\n    from torch.nn.parallel import DistributedDataParallel as DDP\n    from torch.utils.data import DataLoader\n    from snowflake.ml.modeling.distributors.pytorch import get_context  \n    \n    # Get distributed context\n    context = get_context()\n    rank = context.get_rank()\n    local_rank = context.get_local_rank()\n    print(f\"[Rank {rank}] Starting training...\")\n    \n    # Initialize process group\n    backend = 'nccl' if torch.cuda.is_available() else 'gloo'\n    dist.init_process_group(backend=backend)\n    device = torch.device(f\"cuda:{local_rank}\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"[Rank {rank}] Using device: {device}\")\n    \n    # Define model\n    class WaferYieldDNN(nn.Module):\n        def __init__(self, input_size, hidden_size=128):\n            super().__init__()\n            self.network = nn.Sequential(\n                nn.Linear(input_size, hidden_size),\n                nn.ReLU(),\n                nn.BatchNorm1d(hidden_size),\n                nn.Dropout(0.3),\n                nn.Linear(hidden_size, hidden_size // 2),\n                nn.ReLU(),\n                nn.BatchNorm1d(hidden_size // 2),\n                nn.Dropout(0.2),\n                nn.Linear(hidden_size // 2, 1),\n                nn.Sigmoid()\n            )\n        def forward(self, x):\n            return self.network(x)\n    \n    # Create and wrap model with DDP\n    model = WaferYieldDNN(input_size=INPUT_SIZE)                                   \n    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)                         \n    model = model.to(device)                                                       \n    model = DDP(model, device_ids=[local_rank] if torch.cuda.is_available() else None)  \n    \n    # Setup optimizer and loss\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Get data shard for this worker\n    dataset_map = context.get_dataset_map()\n    torch_dataset = dataset_map['train'].get_shard().to_torch_dataset(batch_size=1024)\n    dataloader = DataLoader(torch_dataset, batch_size=None)\n    \n    # Training loop\n    EPOCHS = 25\n    model.train()\n    \n    for epoch in range(EPOCHS):\n        epoch_loss = 0.0\n        num_batches = 0\n        \n        for batch_dict in dataloader:\n\n            if len(batch_dict) == 0:                                                   \n                continue                                                               \n                                                                                \n            features = torch.cat([batch_dict[col].T for col in INPUT_COLS], dim=1).float().to(device)\n            labels = batch_dict[LABEL_COL].T.squeeze(0).float().to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(features).squeeze()\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            epoch_loss += loss.item()\n            num_batches += 1\n        \n        if rank == 0 and (epoch + 1) % 5 == 0:\n            avg_loss = epoch_loss / max(num_batches, 1)\n            print(f\"   Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}\")\n    \n    # Save model (only rank 0)\n    if rank == 0:\n        model_dir = context.get_model_dir()\n        model_path = os.path.join(model_dir, \"wafer_yield_ddp_model.pt\")\n        torch.save(model.module.state_dict(), model_path)\n        print(f\"\\n‚úÖ Model saved to: {model_path}\")\n    \n    dist.destroy_process_group()\n    print(f\"[Rank {rank}] Training complete!\")\n\nprint(\"‚úÖ Training function defined\")\n ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b7e328fb-5be4-4085-a39d-e2aca81894c6",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "# ============================================================================\n# DEFINE DDP TRAINING FUNCTION\n# ============================================================================\n\n# Store column info for access inside training function\nINPUT_COLS = input_cols\nLABEL_COL = label_col\nINPUT_SIZE = len(input_cols)\n\ndef train_ddp_func():\n    \"\"\"DDP training function that runs on each worker.\"\"\"\n    import os\n    import torch\n    import torch.nn as nn\n    import torch.optim as optim\n    import torch.distributed as dist\n    from torch.nn.parallel import DistributedDataParallel as DDP\n    from torch.utils.data import DataLoader\n    from snowflake.ml.modeling.distributors.pytorch import get_context  \n    \n    # Get distributed context\n    context = get_context()\n    rank = context.get_rank()\n    local_rank = context.get_local_rank()\n    print(f\"[Rank {rank}] Starting training...\")\n    \n    # Initialize process group\n    backend = 'nccl' if torch.cuda.is_available() else 'gloo'\n    dist.init_process_group(backend=backend)\n    device = torch.device(f\"cuda:{local_rank}\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"[Rank {rank}] Using device: {device}\")\n    \n    # Define model\n    class WaferYieldDNN(nn.Module):\n        def __init__(self, input_size, hidden_size=128):\n            super().__init__()\n            self.network = nn.Sequential(\n                nn.Linear(input_size, hidden_size),\n                nn.ReLU(),\n                nn.BatchNorm1d(hidden_size),\n                nn.Dropout(0.3),\n                nn.Linear(hidden_size, hidden_size // 2),\n                nn.ReLU(),\n                nn.BatchNorm1d(hidden_size // 2),\n                nn.Dropout(0.2),\n                nn.Linear(hidden_size // 2, 1),\n                nn.Sigmoid()\n            )\n        def forward(self, x):\n            return self.network(x)\n    \n    # Create and wrap model with DDP\n    model = WaferYieldDNN(input_size=INPUT_SIZE)                                   \n    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)                         \n    model = model.to(device)                                                       \n    model = DDP(model, device_ids=[local_rank] if torch.cuda.is_available() else None)  \n    \n    # Setup optimizer and loss\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Get data shard for this worker\n    dataset_map = context.get_dataset_map()\n    torch_dataset = dataset_map['train'].get_shard().to_torch_dataset(batch_size=1024)\n    dataloader = DataLoader(torch_dataset, batch_size=None)\n    \n    # Training loop\n    EPOCHS = 25\n    model.train()\n    \n    for epoch in range(EPOCHS):\n        epoch_loss = 0.0\n        num_batches = 0\n        \n        for batch_dict in dataloader:\n\n            if len(batch_dict) == 0:                                                   \n                continue                                                               \n                                                                                \n            features = torch.stack([batch_dict[col].squeeze() for col in INPUT_COLS], dim=1).float().to(device)\n            labels = batch_dict[LABEL_COL].squeeze().float().to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(features).squeeze()\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            epoch_loss += loss.item()\n            num_batches += 1\n        \n        if rank == 0 and (epoch + 1) % 5 == 0:\n            avg_loss = epoch_loss / max(num_batches, 1)\n            print(f\"   Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}\")\n    \n    # Save model (only rank 0)\n    if rank == 0:\n        model_dir = context.get_model_dir()\n        model_path = os.path.join(model_dir, \"wafer_yield_ddp_model.pt\")\n        torch.save(model.module.state_dict(), model_path)\n        print(f\"\\n‚úÖ Model saved to: {model_path}\")\n    \n    dist.destroy_process_group()\n    print(f\"[Rank {rank}] Training complete!\")\n\nprint(\"‚úÖ Training function defined\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## üìò Section 4 ‚Äî Configure and Launch Distributed Training\n",
    "\n",
    "Use `PyTorchDistributor` with `PyTorchScalingConfig` to configure the distributed training job.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000009"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell11",
    "language": "python"
   },
   "outputs": [],
   "source": "# ============================================================================\n# CONFIGURE PYTORCHDISTRIBUTOR\n# ============================================================================\n\nNUM_NODES = 2                    # Use both nodes in your pool                  \nNUM_WORKERS_PER_NODE = 1         # 1 worker per node (1 GPU per node)           \nNUM_CPUS_PER_WORKER = 4          # CPUs per worker \nNUM_GPUS_PER_WORKER = 1        # 1 GPU per worker                                                              \n\nscaling_config = PyTorchScalingConfig( num_nodes=NUM_NODES,                     \nnum_workers_per_node=NUM_WORKERS_PER_NODE,                                      \nresource_requirements_per_worker=WorkerResourceConfig( num_cpus=NUM_CPUS_PER_WORKER, num_gpus=NUM_GPUS_PER_WORKER ) )                  \n\npytorch_trainer = PyTorchDistributor( train_func=train_ddp_func,                \nscaling_config=scaling_config )                                                 \n\nprint(\"PyTorchDistributor configured\") \nprint(f\"   Nodes: {NUM_NODES}\") \nprint(f\" Workers per node: {NUM_WORKERS_PER_NODE}\") \nprint(f\"   GPUs per worker: {NUM_GPUS_PER_WORKER}\") \nprint(f\"   Total GPUs: {NUM_NODES * NUM_WORKERS_PER_NODE * NUM_GPUS_PER_WORKER}\")   ",
   "id": "ce110000-1111-2222-3333-ffffff000010"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell12",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# ============================================================================\n# RUN DISTRIBUTED TRAINING\n# ============================================================================\n\nprint(\"üöÄ Starting distributed DDP training...\")\nprint(\"=\" * 60)\n\n# Run the distributed training job\n# Pass the data_connector via dataset_map\nresponse = pytorch_trainer.run(\n    dataset_map={'train': sharded_data_connector}\n)\n\nprint(\"=\" * 60)\nprint(\"‚úÖ Distributed training complete!\")\n",
   "id": "ce110000-1111-2222-3333-ffffff000011"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell13",
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## üìò Section 5 ‚Äî Retrieve Trained Model\n",
    "\n",
    "For multi-node DDP, the model is automatically synchronized to a Snowflake stage. Use `get_model_dir()` from the response to locate it.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000012"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell14",
    "language": "python"
   },
   "outputs": [],
   "source": "# ============================================================================\n# RETRIEVE MODEL FROM RESPONSE\n# ============================================================================\n\n# Get the model directory from the training response (this is a stage path)\nmodel_dir = response.get_model_dir()\nprint(f\"üìÅ Model stage location: {model_dir}\")\nprint(f\"‚úÖ Model saved to Snowflake stage and ready for registry\")\n",
   "id": "ce110000-1111-2222-3333-ffffff000013"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell15",
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## üìò Section 6 ‚Äî Multi-Node Model Persistence with Stages\n",
    "\n",
    "For multi-node training, specify an `artifact_stage_location` to persist the model to a Snowflake stage:\n",
    "\n",
    "```python\n",
    "response = pytorch_trainer.run(\n",
    "    dataset_map={'train': data_connector},\n",
    "    artifact_stage_location=\"DB_NAME.SCHEMA_NAME.STAGE_NAME\"\n",
    ")\n",
    "\n",
    "# Model saved at: DB_NAME.SCHEMA_NAME.STAGE_NAME/model/{request_id}/\n",
    "stage_location = response.get_model_dir()\n",
    "```\n",
    "\n",
    "This ensures the model is accessible across nodes and persisted beyond the training session.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000014"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell16",
    "language": "python"
   },
   "outputs": [],
   "source": "# ============================================================================\n# REGISTER MODEL TO SNOWFLAKE MODEL REGISTRY\n# ============================================================================\n\nfrom snowflake.ml.registry import Registry\nimport pandas as pd\n\n# Get the model stage path from training response\nmodel_dir = response.get_model_dir()\nstage_model_path = f\"{model_dir}/wafer_yield_ddp_model.pt\"\n\n# Recreate model architecture and load from stage\ntrained_model = WaferYieldDNN(input_size=len(input_cols))\n\n# Download temporarily just to load state dict\nimport tempfile\nlocal_temp_dir = tempfile.mkdtemp()\nsession.file.get(stage_model_path, local_temp_dir)\n\nimport glob\ndownloaded_files = glob.glob(os.path.join(local_temp_dir, \"*wafer_yield_ddp_model.pt*\"))\nif not downloaded_files:\n    downloaded_files = glob.glob(os.path.join(local_temp_dir, \"*.pt\"))\n    \ntrained_model.load_state_dict(torch.load(downloaded_files[0]))\ntrained_model.eval()\n\nprint(f\"‚úÖ Model loaded from stage: {stage_model_path}\")\nprint(f\"   Parameters: {sum(p.numel() for p in trained_model.parameters()):,}\")\n\n# Create registry\nregistry = Registry(session=session)\n\n# Create sample input for signature inference\nsample_input = pd.DataFrame({col: [0.0] for col in input_cols}).astype('float32')\n\n# Register the model\nmv = registry.log_model(\n    model=trained_model,\n    model_name=\"WAFER_YIELD_DDP_MODEL\",\n    version_name=f\"v_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n    sample_input_data=sample_input,\n    options={\n        \"embed_local_ml_library\": True\n    }\n)\n\nprint(f\"‚úÖ Model registered to Snowflake Model Registry\")\nprint(f\"   Name: {mv.model_name}\")\nprint(f\"   Version: {mv.version_name}\")\n\n# Clean up temp directory\nimport shutil\nshutil.rmtree(local_temp_dir)\n",
   "id": "ce110000-1111-2222-3333-ffffff000015"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell17",
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## üìò Summary\n",
    "\n",
    "### What We Covered\n",
    "\n",
    "| Topic | Snowflake API |\n",
    "|-------|---------------|\n",
    "| **Data Loading** | `ShardedDataConnector` ‚Äî auto-partitions data across workers |\n",
    "| **Training Function** | Standard PyTorch DDP with `get_context()` for rank/device info |\n",
    "| **Orchestration** | `PyTorchDistributor` ‚Äî manages distributed job execution |\n",
    "| **Scaling** | `PyTorchScalingConfig` ‚Äî configure nodes, workers, GPUs |\n",
    "| **Model Persistence** | `artifact_stage_location` ‚Äî sync models to Snowflake stage |\n",
    "| **Model Registry** | `registry.log_model()` ‚Äî register for deployment |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **No cluster management** ‚Äî Snowflake handles all orchestration\n",
    "2. **Standard PyTorch code** ‚Äî Your DDP logic is portable\n",
    "3. **Automatic data sharding** ‚Äî Each worker gets unique data partition\n",
    "4. **Gradient sync handled** ‚Äî DDP wrapper synchronizes automatically\n",
    "5. **Integrated persistence** ‚Äî Models saved to Snowflake stages\n",
    "\n",
    "### When to Use DDP\n",
    "\n",
    "| ‚úÖ Consider DDP | ‚ùå DDP May Not Help |\n",
    "|-----------------|---------------------|\n",
    "| Training epochs take too long | Training already fast |\n",
    "| Multiple GPUs available | Only 1 GPU available |\n",
    "| GPU utilization is high | GPU utilization is low (data bottleneck) |\n",
    "| Model fits on single GPU | Model too large for single GPU (use FSDP) |\n",
    "\n",
    "> **Tip:** Profile your workload first. Use `nvidia-smi` or Snowflake's resource monitoring to identify bottlenecks before adding distributed training complexity.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Register model to Model Registry (Notebook 02)\n",
    "- Deploy model via SPCS (Notebook 03)\n",
    "- Set up ML Jobs and CI/CD (Notebook 04)\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000016"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell18",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# END OF NOTEBOOK 2c\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Notebook 2c Complete: Distributed Data Parallel (DDP)\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"üìä Key APIs Used:\")\n",
    "print(\"   ‚Ä¢ ShardedDataConnector.from_dataframe() ‚Äî Data loading\")\n",
    "print(\"   ‚Ä¢ PyTorchDistributor ‚Äî Distributed training orchestration\")\n",
    "print(\"   ‚Ä¢ PyTorchScalingConfig ‚Äî Resource configuration\")\n",
    "print(\"   ‚Ä¢ get_context() ‚Äî Rank, device, dataset access in workers\")\n",
    "print()\n",
    "print(\"üöÄ DDP enables linear scaling across GPUs for large workloads\")\n",
    "print()\n",
    "print(\"‚û°Ô∏è  For even larger models, explore FSDP (Fully Sharded Data Parallel)\")\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000017"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell19"
   },
   "source": [],
   "id": "ce110000-1111-2222-3333-ffffff000018"
  },
  {
   "cell_type": "markdown",
   "id": "8fb016b1-ce34-4bb0-bfb6-5f75d10000fe",
   "metadata": {
    "name": "cell20"
   },
   "source": ""
  }
 ]
}