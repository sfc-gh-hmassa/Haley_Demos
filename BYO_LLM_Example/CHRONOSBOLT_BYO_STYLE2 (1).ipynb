{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "3l6q3lr3uuvtz6cs2qdk",
   "authorId": "3366391852320",
   "authorName": "HMASSA",
   "authorEmail": "haley.massa@snowflake.com",
   "sessionId": "c6bcd49e-2bc4-4de1-8484-27ca8a3d2367",
   "lastEditTime": 1754590277876
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Bring Your Own Time Series Model for Demand Forecasting\n\nIn this notebook, we will test the Chronos-Bolt model for demand forecasting and later, log it to the Model Registry, and finally create a container service to run inference. The Chronos-Bolt model is a specialized time series forecasting model from Amazon that can perform zero-shot forecasting on various time series data.\n\n",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell2"
   },
   "source": [
    "## Step 1: Test Chronos-Bolt model in this notebook, without creating a service\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell3",
    "language": "python"
   },
   "outputs": [],
   "source": "# Install exact working versions (validated - FIXED torch compatibility)\n%pip install chronos-forecasting==1.5.3 --quiet\n%pip install \"torch>=2.5.0,<2.7.0\" --quiet\n%pip install transformers>=4.53.2 --quiet\n%pip install numpy>=1.26.4 --quiet\n%pip install pandas>=2.2.2 --quiet\n%pip install matplotlib --quiet\n%pip install accelerate>=1.9.0 --quiet\n\nprint(\"✅ Packages installed successfully!\")\n",
   "id": "ce110000-1111-2222-3333-ffffff000002"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell4",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Standard Chronos flow using BaseChronosPipeline\nfrom chronos import BaseChronosPipeline\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nmodel_name = \"amazon/chronos-bolt-base\"\n\n# Load the model with CPU device mapping\npipeline = BaseChronosPipeline.from_pretrained(\n    model_name,\n    device_map=\"cpu\",\n    torch_dtype=torch.float32,\n)\n",
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "id": "053becb7-c992-41b7-ba8a-5a9ac0a0571a",
   "metadata": {
    "language": "python",
    "name": "cell26",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "print(torch.__version__)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell5",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create and test demand forecasting with sample data\n# Generate synthetic demand data\nnp.random.seed(42)\ndays = 150\nbase_demand = 100\ntrend = np.linspace(0, 20, days)\nseasonality = 10 * np.sin(2 * np.pi * np.arange(days) / 7)  # Weekly seasonality\nnoise = np.random.normal(0, 5, days)\ndemand_history = base_demand + trend + seasonality + noise\ndemand_history = np.maximum(demand_history, 0)  # Ensure non-negative\n\nprint(f\"Generated demand history: {len(demand_history)} days\")\nprint(f\"Recent values: {demand_history[-10:].round(2)}\")\n\n# Create forecast\ncontext_length = 120  # Use last 120 days for context\nprediction_length = 30  # Forecast next 30 days\n\n# Convert to torch tensor and add batch dimension\ncontext = torch.tensor(demand_history[-context_length:], dtype=torch.float32).unsqueeze(0)\n\n# Generate forecast (Chronos-Bolt returns multiple samples by default)\nforecast = pipeline.predict(\n    context=context,\n    prediction_length=prediction_length\n)\n\n# Extract median forecast and quantiles using the WORKING approach\n# Forecast shape: [batch_size, num_samples, prediction_length]\nprint(f\"\\nForecast results:\")\nprint(f\"Forecast shape: {forecast.shape}\")  # Should be [1, num_samples, prediction_length]\nprint(f\"Number of samples: {forecast.shape[1]}\")\n\n# Use the working method from ChronosBolt_WorkingVersions.ipynb\nmedian_idx = forecast.shape[1] // 2  # Middle sample as median\nforecast_median = forecast[0, median_idx, :].numpy()\nforecast_lower = forecast[0, 1, :].numpy()  # Second sample as lower bound\nforecast_upper = forecast[0, -2, :].numpy()  # Second-to-last sample as upper bound\n\nprint(f\"Median forecast (first 10 days): {forecast_median[:10].round(2)}\")\nprint(f\"Lower bound (first 5 days): {forecast_lower[:5].round(2)}\")\nprint(f\"Upper bound (first 5 days): {forecast_upper[:5].round(2)}\")\n",
   "id": "ce110000-1111-2222-3333-ffffff000004"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell6",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Visualize the forecast\nplt.figure(figsize=(12, 6))\n\n# Plot historical data\nhistorical_days = range(len(demand_history))\nplt.plot(historical_days, demand_history, label='Historical Demand', color='blue', alpha=0.7)\n\n# Plot forecast\nforecast_days = range(len(demand_history), len(demand_history) + prediction_length)\nplt.plot(forecast_days, forecast_median, label='Forecast (Median)', color='red', linewidth=2)\nplt.fill_between(forecast_days, forecast_lower, forecast_upper, alpha=0.3, color='red', label='Confidence Interval')\n\n# Add vertical line to separate historical from forecast\nplt.axvline(x=len(demand_history)-1, color='gray', linestyle='--', alpha=0.5)\n\nplt.title('Demand Forecasting with Chronos-Bolt')\nplt.xlabel('Days')\nplt.ylabel('Demand')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"✅ Chronos-Bolt model working successfully!\")\n",
   "id": "ce110000-1111-2222-3333-ffffff000005"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell7",
    "collapsed": false
   },
   "source": "## Step 2: Log Chronos-Bolt model to Model Registry\n\nModel Registry Documentation: https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/overview\n\n* Standard HuggingFace Pipelines: https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/built-in-models/hugging-face - the example below constructs a custom model\n* Custom Model Pipeline: https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/bring-your-own-model-types\n",
   "id": "ce110000-1111-2222-3333-ffffff000006"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell8",
    "language": "python"
   },
   "outputs": [],
   "source": "# Build the custom model class\nimport os\nimport torch\nimport pandas as pd\nfrom chronos import BaseChronosPipeline\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import custom_model, model_signature\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()\n\n# Create a custom model class for the instantiation and inference of this model\nclass ChronosBoltModel(custom_model.CustomModel):\n    def __init__(self, context: custom_model.ModelContext) -> None:\n        super().__init__(context)\n\n        # For `chronos` set the environment variables to use local files only\n        # We will download them to a local dir using huggingface_hub\n        os.environ['HF_HUB_OFFLINE'] = '1'\n        os.environ['TRANSFORMERS_OFFLINE'] = '1'\n        \n        self.pipeline = BaseChronosPipeline.from_pretrained(\n            context.path(\"model_path\"),\n            device_map=\"cpu\",\n            torch_dtype=torch.float32,\n        )\n\n    # Inference function with a dataframe as input\n    @custom_model.inference_api\n    def predict(self, input_df: pd.DataFrame) -> pd.DataFrame:\n        results = []\n        \n        for idx, row in input_df.iterrows():\n            try:\n                product_id = row['product_id']\n                demand_history = row['demand_history']\n                prediction_length = int(row.get('prediction_length', 30))\n                \n                # Parse demand history (handle both list and string formats)\n                if isinstance(demand_history, str):\n                    history_values = [float(x.strip()) for x in demand_history.split(',')]\n                else:\n                    history_values = list(demand_history)\n                \n                # Convert to tensor\n                context = torch.tensor(history_values, dtype=torch.float32)\n                \n                # Generate forecast using the WORKING approach\n                with torch.no_grad():\n                    forecast_result = self.pipeline.predict(\n                        context=context.unsqueeze(0),\n                        prediction_length=prediction_length\n                    )\n                \n                # Extract results using the working method\n                median_idx = forecast_result.shape[1] // 2\n                forecast_median = forecast_result[0, median_idx, :].numpy().tolist()\n                forecast_lower = forecast_result[0, 1, :].numpy().tolist()\n                forecast_upper = forecast_result[0, -2, :].numpy().tolist()\n                \n                results.append({\n                    'product_id': product_id,\n                    'forecast_median': forecast_median,\n                    'forecast_lower': forecast_lower,\n                    'forecast_upper': forecast_upper,\n                    'prediction_length': prediction_length,\n                    'model_used': 'chronos-bolt-base'\n                })\n                \n            except Exception as e:\n                results.append({\n                    'product_id': row.get('product_id', f'error_{idx}'),\n                    'forecast_median': [],\n                    'forecast_lower': [],\n                    'forecast_upper': [],\n                    'prediction_length': 0,\n                    'model_used': 'error',\n                    'error': str(e)\n                })\n        \n        return pd.DataFrame(results)\n",
   "id": "ce110000-1111-2222-3333-ffffff000007"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell9",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Download the model from huggingface to a local directory\n# TO USE YOUR OWN MODEL, skip this step and pass in the model directory path in the place of \n# `local_model_location`. Finally instantiate the CustomModel class.\nimport tempfile\nfrom huggingface_hub import snapshot_download\n\ntmpdir = tempfile.mkdtemp()\nlocal_model_location = snapshot_download(\n    repo_id=model_name,\n    local_dir=tmpdir\n)\n\npath_list = {\"model_path\": local_model_location}\nchronos_model = ChronosBoltModel(context=custom_model.ModelContext(artifacts=path_list))\n\n",
   "id": "ce110000-1111-2222-3333-ffffff000008"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell10",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Generate a forecast from the model using the predict() method\ntest_input = pd.DataFrame({\n    'product_id': ['DEMO_PRODUCT_001', 'DEMO_PRODUCT_002'],\n    'demand_history': [demand_history[-60:].tolist(), (demand_history[-60:] * 1.2).tolist()],\n    'prediction_length': [14, 14]\n})\n\nresponse = chronos_model.predict(test_input)\nprint(\"✅ Model prediction results:\")\nprint(response)\nprint(f\"\\n📊 Forecast summary:\")\nfor _, row in response.iterrows():\n    print(f\"Product {row['product_id']}: {len(row['forecast_median'])} day forecast\")\n    if row['forecast_median']:\n        print(f\"  First 5 days: {[round(x, 2) for x in row['forecast_median'][:5]]}\")\n",
   "id": "ce110000-1111-2222-3333-ffffff000009"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell11",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Infer the model signature from the input and the response above.\n# Documentation: https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/model-signature\nsignature = model_signature.infer_signature(test_input, response)\n",
   "id": "ce110000-1111-2222-3333-ffffff000010"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell12",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Log the model to the Snowflake Model Registry\nreg = Registry(session)\nmv = reg.log_model(\n    chronos_model,\n    model_name='CHRONOS_BOLT_DEMAND_FORECASTING',\n    version_name='V6',  # Can remove this parameter to auto-create version names\n    pip_requirements=[\n        'chronos-forecasting==1.5.3',\n        'torch>=2.5.0,<2.7.0',\n        'transformers>=4.53.2',\n        'pandas>=2.2.2',\n        'numpy>=1.26.4',\n        'accelerate>=1.9.0',\n        'huggingface_hub',\n        'snowflake-ml-python'\n    ],\n    signatures={\"predict\": signature},\n    options={\"enable_remote_image_build\": True}\n)",
   "id": "ce110000-1111-2222-3333-ffffff000011"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell13",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# This step SHOULD fail!!\n# The default for models is to predict using a warehouse, however, these models will need container services for proper resource allocation\nmv.run(test_input)\n",
   "id": "ce110000-1111-2222-3333-ffffff000012"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell14",
    "collapsed": false
   },
   "source": [
    "## 3. Create a Container Service for Model Serving\n",
    "\n",
    "Read more here: https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/container\n",
    "\n",
    "*>>> Important Note: This is a long-running service, so once you are done, you will want to suspend the service to stop incurring costs. To do this, run `ALTER SERVICE CHRONOS_SERVICE SUSPEND;` in a Notebook or SQL worksheet*\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000013"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell15",
    "language": "python"
   },
   "outputs": [],
   "source": "# Create a compute pool for CPU access to run this service\n\n# Compute Pool definition\nDATABASE_NAME = 'DEMODB'\nSCHEMA_NAME = 'WATER_FORECAST'\nIMAGE_REPO_NAME = \"CHRONOS_SERVICE_REPO\"\nCOMPUTE_POOL_NAME = \"CHRONOS_SERVICE_POOL_M\"\nCOMPUTE_POOL_NODES = 1\nCOMPUTE_POOL_INSTANCE_TYPE = 'CPU_X64_M'\n\nsession.sql(f\"use database {DATABASE_NAME};\").collect()\nsession.sql(f\"use schema {SCHEMA_NAME};\").collect()\nsession.sql(f\"create image repository if not exists {IMAGE_REPO_NAME}\").collect()\nsession.sql(f\"alter compute pool if exists {COMPUTE_POOL_NAME} stop all\").collect()\nsession.sql(f\"drop compute pool if exists {COMPUTE_POOL_NAME}\").collect()\nsession.sql(f\"create compute pool if not exists {COMPUTE_POOL_NAME} min_nodes={COMPUTE_POOL_NODES} \" +\n            f\"max_nodes={COMPUTE_POOL_NODES} instance_family={COMPUTE_POOL_INSTANCE_TYPE} \" +\n            f\"initially_suspended=True auto_resume=True auto_suspend_secs=300\").collect()\n",
   "id": "ce110000-1111-2222-3333-ffffff000014"
  },
  {
   "cell_type": "code",
   "id": "22474c9f-a942-4610-8d8a-18b6126d63e5",
   "metadata": {
    "language": "python",
    "name": "cell25",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import logging\n\n# Basic setup - just fix the syntax error\nlogging.getLogger().setLevel(logging.INFO)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell16",
    "language": "python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a Service object that can be called easily\n",
    "# Name of the Service for powering inference\n",
    "SERVICE_NAME = 'CHRONOS_SERVICE'\n",
    "\n",
    "# **This step may take >15 mins** - it is building a full container runtime.\n",
    "mv.create_service(\n",
    "    service_name=SERVICE_NAME,\n",
    "    service_compute_pool=COMPUTE_POOL_NAME,\n",
    "    image_repo=IMAGE_REPO_NAME,\n",
    "    ingress_enabled=True,\n",
    "    max_instances=int(COMPUTE_POOL_NODES),\n",
    "    build_external_access_integration='ALLOW_ALL_INTEGRATION'\n",
    ")\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000015"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell17",
    "collapsed": false
   },
   "source": [
    "## 4. Serve model from Registry and use for Inference\n",
    "This code can be used in other places like a streamlit app or from a SQL worksheet to call the Chronos-Bolt model\n",
    "\n",
    "Documentation link: https://docs.snowflake.com/en/developer-guide/snowflake-ml/model-registry/container#using-a-model-deployed-to-spcs\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000016"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell18",
    "language": "python"
   },
   "outputs": [],
   "source": "# PYTHON CALL - useful for Streamlit app\n# Pull Model from Registry for Inference\nfrom snowflake.ml.registry import Registry\nfrom snowflake.snowpark.context import get_active_session\n\n# Modify these based on your details.\nDATABASE_NAME = 'DEMODB'\nSCHEMA_NAME = 'WATER_FORECAST'\nSELECTED_MODEL = 'CHRONOS_BOLT_DEMAND_FORECASTING'\nMODEL_VERSION = 'V5'\n\nsession = get_active_session()\nreg = Registry(session=session, database_name=DATABASE_NAME, schema_name=SCHEMA_NAME)\nchronos_from_registry = reg.get_model(SELECTED_MODEL).version(MODEL_VERSION)\n\nchronos_from_registry.run(test_input, service_name=SERVICE_NAME)\n",
   "id": "ce110000-1111-2222-3333-ffffff000017"
  },
  {
   "cell_type": "code",
   "id": "d02d6094-61ff-4271-9659-ffd1d67cd370",
   "metadata": {
    "language": "sql",
    "name": "cell19",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "USE DATABASE DEMODB;\nUSE SCHEMA WATER_FORECAST; \n\nSHOW SERVICES;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed85c5f1-3d78-4604-be68-06b65ed27696",
   "metadata": {
    "language": "sql",
    "name": "cell27",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Example of running the SQL:\nUSE DATABASE DEMODB;\nUSE SCHEMA WATER_FORECAST; \n\nSELECT CHRONOS_SERVICE!PREDICT(\n    'TEST_PRODUCT_001',\n    ARRAY_CONSTRUCT(100, 105, 98, 110, 95, 102, 108, 97, 115, 92, 120),\n    7\n) as forecast_result;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell22",
    "collapsed": false
   },
   "source": [
    "## 5. Cost Management - Suspend Services\n",
    "\n",
    "*>>> IMPORTANT: Remember to suspend the service when done to avoid ongoing costs!*\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000021"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "cell23",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- SUSPEND SERVICE TO STOP COSTS\n\n\nALTER SERVICE CHRONOS_SERVICE SUSPEND;\n\n-- SUSPEND COMPUTE POOL\nALTER COMPUTE POOL CHRONOS_SERVICE_POOL_M SUSPEND;\n\n-- Check status\nSHOW SERVICES LIKE 'CHRONOS_SERVICE';\nSHOW COMPUTE POOLS LIKE 'CHRONOS_SERVICE_POOL_M';\n",
   "id": "ce110000-1111-2222-3333-ffffff000022"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "cell24",
    "language": "sql",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": [
    "-- RESUME SERVICES (when needed for inference)\n",
    "-- ALTER COMPUTE POOL CHRONOS_SERVICE_POOL_M RESUME;\n",
    "-- ALTER SERVICE CHRONOS_SERVICE RESUME;\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000023"
  }
 ]
}